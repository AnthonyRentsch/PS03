---
title: "STAT/MATH 495: Problem Set 03"
author: "Anthony Rentsch"
date: "2017-09-26"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5)

# Load packages
library(tidyverse)
library(plyr)
data1 <- read.csv("data/data1.csv")
data2 <- read.csv("data/data2.csv")
```


# Question

For both `data1` and `data2` tibbles (a tibble is a data frame with some
[metadata](https://blog.rstudio.com/2016/03/24/tibble-1-0-0#tibbles-vs-data-frames) attached):

* Find the splines model with the best out-of-sample predictive ability.
* Create a visualizaztion arguing why you chose this particular model.
* Create a visualizaztion of this model plotted over the given $(x_i, y_i)$ points for $i=1,\ldots,n=3000$.
* Give your estimate $\widehat{\sigma}$ of $\sigma$ where the noise component $\epsilon_i$ is distributed with mean 0 and standard deviation $\sigma$.

# Create Crossvalidation Function

This function takes in two parameters: a data set to train the model on and a data set to validate the model on. It returns a data frame with the root mean squared error (RMSE) for every possible value of degrees of freedom, up to 100. I chose 100 as the maximum degrees of freedom to speed up computation and make visuals easier to interpret.
```{r}
crossvalidate <- function(train, test){
  storage <- data.frame()
  preds <- NULL
  i <- 2
  while(i <= 100){
    model <- smooth.spline(x = train$x,y = train$y, df=i)
    new_data <- test$x
    preds <- predict(model, new_data)
    preds <- as.data.frame(preds)
    preds <- cbind(preds, y_obs = test$y)
    RMSE <- sqrt(mean(preds$y_obs - preds$y)^2)
    new_row <- c(i, RMSE)
    storage <- rbind(storage, new_row)
    i = i + 1
  }
  names(storage) <- c("df","RMSE")
  return(storage)
}
```

# Data 1

Here I will run the crossvalidation function five times for data1, training on four-fifths of the data and validating on the other fifth, and then switching which one-fifth of the data is withheld from training.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
#split data1 into 5 parts
set.seed(1)
groups <- sample(1:5, size = nrow(data1), replace=T, prob=c(0.2,0.2,0.2,0.2,0.2))
data11 <- data1[groups==1,]
data12 <- data1[groups==2,]
data13 <- data1[groups==3,]
data14 <- data1[groups==4,]
data15 <- data1[groups==5,]

#run the crossvalidation
fold1_data1 <- crossvalidate(data1[groups != 1,], data11)
fold2_data1 <- crossvalidate(data1[groups != 2,], data12)
fold3_data1 <- crossvalidate(data1[groups != 3,], data13)
fold4_data1 <- crossvalidate(data1[groups != 4,], data14)
fold5_data1 <- crossvalidate(data1[groups != 5,], data15)
```

Now let's combine the five folds and calculate the average RMSE for each degree of freedom of the spline model.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
data1_folds <- join_all(list(fold1_data1, fold2_data1, fold3_data1, fold4_data1, fold5_data1), by = "df")
names(data1_folds) <- c("df","fold1","fold2","fold3","fold4","fold5")
data1_folds$meanRMSE <- (data1_folds$fold1 + data1_folds$fold2 + data1_folds$fold3 + data1_folds$fold4 + 
                           data1_folds$fold5)/5
```

Let's visualize this. Which value of degrees of freeom gives us the lowest average out-of-sample RMSE?
```{r, echo=TRUE, warning=FALSE, message=FALSE}
min_point <- data1_folds[which(data1_folds$meanRMSE == min(data1_folds$meanRMSE)),]

ggplot() +
  geom_line(data = data1_folds, aes(x = df, y = meanRMSE)) +
  geom_point(data = min_point, aes(x = df, y = meanRMSE), colour = "red") +
  geom_label(data = min_point, 
             aes(df, meanRMSE, label = paste0("(",df,","," ",round(meanRMSE,5),")",sep="")),
             fontface = "bold", fill = "grey90", label.size = 0, nudge_x = 10, nudge_y = -0.05) +
  geom_segment(data = min_point, aes(x = df, y = 0, xend = df, yend = meanRMSE), 
               colour = "red", linetype = "dashed") +
  geom_segment(data = min_point, aes(x = 0, y = meanRMSE, xend = df, yend = meanRMSE), 
               colour = "red", linetype = "dashed") +
  labs(title = "Crossvalidation for data1", x = "degrees of freedom", y = "mean RMSE") +
  theme(plot.title = element_text(hjust = 0.5))
```

The crossvalidation indicates that a spline model with 13 degrees of freedom gives us the lowest out-of-sample error (RMSE equals roughly 0.42491, which is my estimate for $\sigma$, the standard deviation of the noise component of the model) for data1. Below is a plot of this model against the actual data.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
spline.data1 <- smooth.spline(x = data1$x,y = data1$y, df=min_point$df) %>% broom::augment()
  
ggplot() +
  geom_point(data = data1, aes(x = x, y = y)) +
  geom_line(data = spline.data1, aes(x = x, y = .fitted), colour = "#FB4D42", size = 2)
```
To sum up, for data1, crossvalidation indicates that the best splines model has:

* degrees of freedom = 13
* $\widehat{\sigma}$ = 0.42491

# Data 2

Now I'll move on and repeat this procedure for data2.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
#split data2 into 5 parts
set.seed(2)
groups <- sample(1:5, size = nrow(data1), replace=T, prob=c(0.2,0.2,0.2,0.2,0.2))
data21 <- data2[groups==1,]
data22 <- data2[groups==2,]
data23 <- data2[groups==3,]
data24 <- data2[groups==4,]
data25 <- data2[groups==5,]

#use crossvalidation function
fold1_data2 <- crossvalidate(data2[groups != 1,], data21)
fold2_data2 <- crossvalidate(data2[groups != 2,], data22)
fold3_data2 <- crossvalidate(data1[groups != 3,], data23)
fold4_data2 <- crossvalidate(data2[groups != 4,], data24)
fold5_data2 <- crossvalidate(data2[groups != 5,], data25)
```

Again, let's combine the five folds and calculate the average RMSE for each degree of freedom of the spline model.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
data2_folds <- join_all(list(fold1_data2, fold2_data2, fold3_data2, fold4_data2, fold5_data2), by = "df")
names(data2_folds) <- c("df","fold1","fold2","fold3","fold4","fold5")
data2_folds$meanRMSE <- (data2_folds$fold1 + data2_folds$fold2 + data2_folds$fold3 + data2_folds$fold4 + 
                           data2_folds$fold5)/5
```

And again, let's visualize which value of degrees of freedom gives us the lowest average out-of-sample RMSE.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
min_point <- data2_folds[which(data2_folds$meanRMSE == min(data2_folds$meanRMSE)),]

ggplot() +
  geom_line(data = data2_folds, aes(x = df ,y = meanRMSE)) +
  geom_point(data = min_point, aes(x = df, y = meanRMSE), colour = "red") +
  geom_label(data = min_point, 
             aes(df, meanRMSE, label = paste0("(",df,","," ",round(meanRMSE,5),")",sep="")),
             fontface = "bold", fill = "grey90", label.size = 0, nudge_x = 10, nudge_y = -0.05) +
  geom_segment(data = min_point, aes(x = df, y = 0, xend = df, yend = meanRMSE), 
               colour = "red", linetype = "dashed") +
  geom_segment(data = min_point, aes(x = 0, y = meanRMSE, xend = df, yend = meanRMSE), 
               colour = "red", linetype = "dashed") +
  labs(title = "Crossvalidation for data2", x = "degrees of freedom", y = "mean RMSE") +
  theme(plot.title = element_text(hjust = 0.5))
```

The crossvalidation indicates that a spline model with 15 degrees of freedom gives us the lowest out-of-sample error (RMSE equals roughly 1.32558, which is my estimate for $\sigma$, the standard deviation of the noise component of the model). Below is a plot of this model against the actual data.
```{r, echo=TRUE, warning=FALSE, message=FALSE}
spline.data2 <- smooth.spline(x = data2$x,y = data2$y, df=min_point$df) %>% broom::augment()
  
ggplot() +
  geom_point(data = data2, aes(x = x, y = y)) +
  geom_line(data = spline.data2, aes(x = x, y = .fitted), colour = "#FB4D42", size = 2)
```

To sum up, for data2, crossvalidation indicates that the best splines model has:

* degrees of freedom = 15
* $\widehat{\sigma}$ = 1.32558